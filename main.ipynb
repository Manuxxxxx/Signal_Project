{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imgTransformations\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from ipywidgets import FloatSlider, IntSlider, Output, VBox, Tab, interactive, Button, Label, SelectionSlider, Dropdown\n",
    "import ipywidgets as widgets\n",
    "import textwrap\n",
    "import utils\n",
    "import numpy as np\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirname = os.path.abspath('')\n",
    "# folder = os.path.join(dirname, 'MEFDatabase/source image sequences/Farmhouse_hdr-project.com/')\n",
    "folder = os.path.join(dirname, 'MEFDatabase/source image sequences/')\n",
    "entries = os.listdir(folder)\n",
    "subfolders = [entry for entry in entries if os.path.isdir(os.path.join(folder, entry))]\n",
    "images = []\n",
    "\n",
    "def interactive_image_select(subfolder):\n",
    "    global images\n",
    "    imgSet = os.path.join(folder, subfolder)\n",
    "    images = utils.load_images_from_folder(os.path.join(dirname, imgSet))\n",
    "    images_per_row = 3\n",
    "\n",
    "    num_inputs = len(images)\n",
    "\n",
    "    # Calculate the number of rows needed for inputs and results\n",
    "    input_rows = (num_inputs + images_per_row - 1) // images_per_row\n",
    "\n",
    "    # Create the figure and axes\n",
    "    fig, axes = plt.subplots(input_rows, images_per_row, figsize=(20,20))\n",
    "    axes = axes.flatten()  # Flatten to easily iterate over all axes\n",
    "    # Plot input images\n",
    "    for i, img in enumerate(images):\n",
    "        ax = axes[i]\n",
    "        ax.imshow(img)\n",
    "        ax.set_title(f'Input {i + 1}')\n",
    "        ax.axis('off')\n",
    "\n",
    "selectionWidget = interactive(interactive_image_select,\n",
    "                              subfolder = Dropdown(\n",
    "                                  options = subfolders,\n",
    "                                  value = 'Farmhouse_hdr-project.com',\n",
    "                                  description = 'Image set',\n",
    "                                  disabled = False\n",
    "                              )\n",
    "                              )\n",
    "display(selectionWidget)\n",
    "\n",
    "# images = utils.load_images_from_folder(folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import transformations._transformations\n",
    "\n",
    "def interactive_average_fusion():\n",
    "    title, fused = imgTransformations.average_fusion(images)\n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.imshow(fused)\n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "def interactive_mertens_fusion():\n",
    "    title, fused = imgTransformations.mertens_fusion(images)\n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.imshow(fused)\n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "def interactive_exposure_fusion():\n",
    "    title, fused = imgTransformations.exposure_fusion(images)\n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.imshow(fused)\n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "def interactive_exposure_compensation_fusion():\n",
    "    title, fused = imgTransformations.exposure_compensation_fusion(images)\n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.imshow(fused)\n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Functions with numeric parameters\n",
    "def interactive_laplacian_pyramid_fusion(levels):\n",
    "    title, fused = imgTransformations.laplacian_pyramid_fusion(images, levels=levels)\n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.imshow(fused)\n",
    "    plt.title(f\"{title} (levels: {levels})\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "def interactive_enhanced_exposure_fusion(sigma, epsilon, kernel_dim):\n",
    "    title, fused = imgTransformations.enhanced_exposure_fusion(images, sigma=sigma, epsilon=epsilon, blur_kernel=(kernel_dim,kernel_dim))\n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.imshow(fused)\n",
    "    plt.title(f\"{title} (sigma: {sigma:.2f}, epsilon: {epsilon})\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "def interactive_domain_transform_fusion(sigmaSpatial, sigmaColor, epsilon):\n",
    "    title, fused = imgTransformations.domain_transform_fusion(images, sigmaSpatial=sigmaSpatial, sigmaColor=sigmaColor, epsilon=epsilon, homebrew_dt=False)\n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.imshow(fused)\n",
    "    plt.title(f\"{title} (sigmaSpatial: {sigmaSpatial}, sigmaColor: {sigmaColor}, epsilon: {epsilon})\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "def interactive_wavelet_fusion(level):\n",
    "    title, fused = imgTransformations.wavelet_fusion(images, wavelet='db1', level=level)\n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.imshow(fused)\n",
    "    plt.title(f\"{title} (level: {level})\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "def interactive_dt_filter(sigmaSpatial, sigmaColor, num_iterations):\n",
    "    guidance = cv2.cvtColor(images[0], cv2.COLOR_BGR2RGB).astype(np.float32)/255.0\n",
    "    src = cv2.cvtColor(images[0], cv2.COLOR_BGR2GRAY).astype(np.float32)/255.0\n",
    "    filtered = cv2.dt_filter(guidance, src, sigmaSpatial=sigmaSpatial, sigmaColor=sigmaColor, num_iterations=num_iterations)\n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.imshow(filtered, cmap='gray')\n",
    "    plt.title(f\"dt_filter (sigmaSpatial: {sigmaSpatial}, sigmaColor: {sigmaColor}, iterations: {num_iterations})\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# --------------------------\n",
    "# Create interactive widgets\n",
    "# --------------------------\n",
    "\n",
    "epsilon_values = np.round(np.logspace(-7, -5, num=10), decimals=10)\n",
    "\n",
    "# Ensure the default value is in the list\n",
    "default_epsilon = 1e-6\n",
    "if default_epsilon not in epsilon_values:\n",
    "    epsilon_values = np.append(epsilon_values, default_epsilon)\n",
    "    epsilon_values = np.sort(epsilon_values)  # Keep sorted order\n",
    "\n",
    "\n",
    "laplacian_widget = interactive(interactive_laplacian_pyramid_fusion, levels=IntSlider(min=1, max=10, step=1, value=4, description='Levels:'))\n",
    "enhanced_widget = interactive(interactive_enhanced_exposure_fusion, \n",
    "                            sigma=FloatSlider(min=0.1, max=1.0, step=0.05, value=0.2, description='Sigma:'), \n",
    "                            epsilon=SelectionSlider(\n",
    "                                options=[(f\"{e:.1e}\", e) for e in epsilon_values],  # Display as scientific notation\n",
    "                                value=default_epsilon,\n",
    "                                description=\"Epsilon:\"\n",
    "                            ),\n",
    "                            kernel_dim = IntSlider(min=1, max=9, step=2, value=3, description=\"Kernel dimension:\"))\n",
    "domain_widget = interactive(interactive_domain_transform_fusion, \n",
    "                            sigmaSpatial=FloatSlider(min=10, max=100, step=5, value=60, description='sigmaSpatial:'), \n",
    "                            sigmaColor=FloatSlider(min=0.1, max=1.0, step=0.05, value=0.4, description='sigmaColor:'), \n",
    "                            epsilon=SelectionSlider(\n",
    "                                options=[(f\"{e:.1e}\", e) for e in epsilon_values],  # Display as scientific notation\n",
    "                                value=default_epsilon,\n",
    "                                description=\"Epsilon:\"\n",
    "                            ))\n",
    "wavelet_widget = interactive(interactive_wavelet_fusion, level=IntSlider(min=1, max=5, step=1, value=2, description='Level:'))\n",
    "\n",
    "# For functions without adjustable numeric parameters, use buttons.\n",
    "avg_button = Button(description=\"Run Average Fusion\")\n",
    "mertens_button = Button(description=\"Run Mertens Fusion\")\n",
    "exposure_button = Button(description=\"Run Exposure Fusion\")\n",
    "exp_comp_button = Button(description=\"Run Exposure Compensation Fusion\")\n",
    "\n",
    "out_avg = Output()\n",
    "out_mertens = Output()\n",
    "out_exposure = Output()\n",
    "out_exp_comp = Output()\n",
    "\n",
    "def run_avg(b):\n",
    "    with out_avg:\n",
    "        out_avg.clear_output(wait=True)\n",
    "        interactive_average_fusion()\n",
    "def run_mertens(b):\n",
    "    with out_mertens:\n",
    "        out_mertens.clear_output(wait=True)\n",
    "        interactive_mertens_fusion()\n",
    "def run_exposure(b):\n",
    "    with out_exposure:\n",
    "        out_exposure.clear_output(wait=True)\n",
    "        interactive_exposure_fusion()\n",
    "def run_exp_comp(b):\n",
    "    with out_exp_comp:\n",
    "        out_exp_comp.clear_output(wait=True)\n",
    "        interactive_exposure_compensation_fusion()\n",
    "\n",
    "avg_button.on_click(run_avg)\n",
    "mertens_button.on_click(run_mertens)\n",
    "exposure_button.on_click(run_exposure)\n",
    "exp_comp_button.on_click(run_exp_comp)\n",
    "\n",
    "# --------------------------\n",
    "# Layout the widgets in a Tabbed interface\n",
    "# --------------------------\n",
    "tab = Tab(children=[\n",
    "    VBox([Label(\"Average Fusion (no parameters):\"), avg_button, out_avg]),\n",
    "    VBox([Label(\"Mertens Fusion (no parameters):\"), mertens_button, out_mertens]),\n",
    "    VBox([Label(\"Laplacian Pyramid Fusion:\"), laplacian_widget]),\n",
    "    VBox([Label(\"Exposure Fusion (no parameters):\"), exposure_button, out_exposure]),\n",
    "    VBox([Label(\"Exposure Compensation Fusion (no parameters):\"), exp_comp_button, out_exp_comp]),\n",
    "    VBox([Label(\"Enhanced Exposure Fusion:\"), enhanced_widget]),\n",
    "    VBox([Label(\"Domain Transform Fusion:\"), domain_widget]),\n",
    "    VBox([Label(\"Wavelet Fusion:\"), wavelet_widget]),\n",
    "])\n",
    "tab.set_title(0, \"Average\")\n",
    "tab.set_title(1, \"Mertens\")\n",
    "tab.set_title(2, \"Laplacian\")\n",
    "tab.set_title(3, \"Exposure\")\n",
    "tab.set_title(4, \"Exp. Comp.\")\n",
    "tab.set_title(5, \"Enhanced\")\n",
    "tab.set_title(6, \"Domain Trans.\")\n",
    "tab.set_title(7, \"Wavelet\")\n",
    "\n",
    "display(tab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "out = Output()\n",
    "\n",
    "def show_weight_maps(image_index):\n",
    "    \"\"\"Function to compute and display weight maps for a given image index.\"\"\"\n",
    "    img = images[image_index]\n",
    "    epsilon = 1e-6\n",
    "\n",
    "    guidance = cv2.cvtColor(img, cv2.COLOR_BGR2RGB).astype(np.float32) / 255.0\n",
    "\n",
    "    gray = cv2.cvtColor((img * 255).astype(np.uint8), cv2.COLOR_RGB2GRAY)\n",
    "    contrast = np.abs(cv2.Laplacian(gray, cv2.CV_32F))\n",
    "\n",
    "    saturation = np.std(img, axis=2)\n",
    "\n",
    "    well_exposedness = np.exp(-0.5 * ((img - 0.5) / 0.2) ** 2)\n",
    "    well_exposedness = np.prod(well_exposedness, axis=2)\n",
    "\n",
    "    weight = (contrast + epsilon) * (saturation + epsilon) * (well_exposedness + epsilon)\n",
    "\n",
    "    # Apply Homebrew Domain Transform filter\n",
    "    smooth_weight_homebrew = imgTransformations.dt_filter_homebrew(guidance, weight, sigmaSpatial=60, sigmaColor=0.4, num_iterations=2)\n",
    "\n",
    "    # Apply OpenCV's dtFilter\n",
    "    smooth_weight_opencv = cv2.ximgproc.dtFilter(img, weight.astype(np.float32), sigmaSpatial=60, sigmaColor=0.4, mode=1)\n",
    "\n",
    "    with out:\n",
    "        out.clear_output(wait=True)\n",
    "        plt.figure(figsize=(18, 5))\n",
    "\n",
    "        # Original Weight Map\n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.imshow(weight, cmap='gray')\n",
    "        plt.title(f\"Original Weight Map (Image {image_index})\")\n",
    "        plt.axis('off')\n",
    "\n",
    "        # Homebrew Domain Transform\n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.imshow(smooth_weight_homebrew, cmap='gray')\n",
    "        plt.title(f\"Smoothed Weight Map (Homebrew DT, Image {image_index})\")\n",
    "        plt.axis('off')\n",
    "\n",
    "        # OpenCV dtFilter\n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.imshow(smooth_weight_opencv, cmap='gray')\n",
    "        plt.title(f\"Smoothed Weight Map (OpenCV dtFilter, Image {image_index})\")\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# Create buttons dynamically\n",
    "buttons = []\n",
    "for i in range(len(images)):\n",
    "    btn = Button(description=f\"Show Image {i}\")\n",
    "    btn.on_click(lambda b, idx=i: show_weight_maps(idx))  # Capture correct index\n",
    "    buttons.append(btn)\n",
    "\n",
    "# Display buttons and output widget\n",
    "display(VBox(buttons + [out]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#comparison between homebrew and opencv dt filter\n",
    "title, fused = imgTransformations.domain_transform_fusion(images, homebrew_dt=False)\n",
    "title_hb, fused_hb = imgTransformations.domain_transform_fusion(images, homebrew_dt=True)\n",
    "\n",
    "plt.figure(figsize=(18, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(fused)\n",
    "plt.title(title)\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(fused_hb)\n",
    "plt.title(title_hb)\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_entropy(image):\n",
    "    \"\"\"Calculates entropy for an RGB image by averaging entropy across channels.\"\"\"\n",
    "    entropy_values = []\n",
    "    for channel in range(image.shape[-1]):  # Loop through R, G, B channels\n",
    "        hist, _ = np.histogram(image[:, :, channel].ravel(), bins=256, range=(0, 256))\n",
    "        hist = hist.astype(np.float32) / hist.sum()\n",
    "        hist = hist[hist > 0]  # Remove zero probabilities\n",
    "        entropy_values.append(-np.sum(hist * np.log2(hist)))\n",
    "    return np.mean(entropy_values)  # Average entropy across channels\n",
    "\n",
    "def spatial_frequency(image):\n",
    "    \"\"\"Calculates spatial frequency for an RGB image.\"\"\"\n",
    "    sf_values = []\n",
    "    for channel in range(image.shape[-1]):  # Compute SF for each color channel\n",
    "        rows, cols = image.shape[:2]\n",
    "        row_freq = np.sqrt(np.sum(np.diff(image[:, :, channel], axis=0) ** 2) / (rows * cols))\n",
    "        col_freq = np.sqrt(np.sum(np.diff(image[:, :, channel], axis=1) ** 2) / (rows * cols))\n",
    "        sf_values.append(np.sqrt(row_freq**2 + col_freq**2))\n",
    "    return np.mean(sf_values)  # Average SF across channels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.metrics import structural_similarity as ssim\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "import pandas as pd\n",
    "\n",
    "# Define available fusion methods with their display names\n",
    "fusion_methods = [\n",
    "    ('Average Fusion', imgTransformations.average_fusion),\n",
    "    ('Mertens Fusion', imgTransformations.mertens_fusion),\n",
    "    ('Laplacian Pyramid', imgTransformations.laplacian_pyramid_fusion),\n",
    "    ('Exposure Fusion', imgTransformations.exposure_fusion),\n",
    "    ('Exposure Compensation', imgTransformations.exposure_compensation_fusion),\n",
    "    ('Enhanced Exposure', imgTransformations.enhanced_exposure_fusion),\n",
    "    ('Domain Transform', imgTransformations.domain_transform_fusion),\n",
    "    ('Domain Transform - Homebrew', imgTransformations.domain_transform_fusion),\n",
    "    ('Wavelet Fusion', imgTransformations.wavelet_fusion)\n",
    "]\n",
    "\n",
    "# Create checkboxes for method selection\n",
    "method_checkboxes = [widgets.Checkbox(description=name, value=False) for name, _ in fusion_methods]\n",
    "checkboxes_box = widgets.VBox([widgets.Label(\"Select Fusion Methods:\")] + method_checkboxes)\n",
    "\n",
    "# Create compare button\n",
    "compare_button = widgets.Button(description=\"Compare Selected Methods\")\n",
    "output = widgets.Output()\n",
    "\n",
    "def calculate_metrics(img1, img2):\n",
    "    \"\"\"Calculate similarity metrics between two images\"\"\"\n",
    "    if img1.shape != img2.shape:\n",
    "        img2 = cv2.resize(img2, (img1.shape[1], img1.shape[0]))\n",
    "    \n",
    "    # Convert to grayscale for SSIM/PSNR\n",
    "    gray1 = cv2.cvtColor(img1, cv2.COLOR_RGB2GRAY)\n",
    "    gray2 = cv2.cvtColor(img2, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    # Calculate SSIM\n",
    "    ssim_value = ssim(gray1, gray2, data_range=255)\n",
    "    \n",
    "    # Calculate PSNR with error handling\n",
    "    mse = np.mean((gray1 - gray2) ** 2)\n",
    "    if mse == 0:\n",
    "        psnr_value = np.inf\n",
    "    else:\n",
    "        with np.errstate(divide='ignore'):\n",
    "            psnr_value = 20 * np.log10(255) - 10 * np.log10(mse)\n",
    "    \n",
    "    return ssim_value, psnr_value\n",
    "\n",
    "def on_compare_button_clicked(b):\n",
    "    with output:\n",
    "        clear_output(wait=True)\n",
    "        selected_methods = [(name, func) for (name, func), cb in zip(fusion_methods, method_checkboxes) if cb.value]\n",
    "        \n",
    "        if len(selected_methods) < 2:\n",
    "            print(\"Please select at least 2 methods!\")\n",
    "            return\n",
    "        \n",
    "        # Generate fused images\n",
    "        results = []\n",
    "        for name, func in selected_methods:\n",
    "            try:\n",
    "                # Handle methods with required parameters\n",
    "                if func == imgTransformations.laplacian_pyramid_fusion:\n",
    "                    title, fused = func(images, levels=4)\n",
    "                elif func == imgTransformations.enhanced_exposure_fusion:\n",
    "                    title, fused = func(images, sigma=0.2, epsilon=1e-6)\n",
    "                elif name == 'Domain Transform - Homebrew':\n",
    "                    title, fused = func(images, sigmaSpatial=60, sigmaColor=0.4, homebrew_dt=True)\n",
    "                elif func == imgTransformations.domain_transform_fusion:\n",
    "                    title, fused = func(images, sigmaSpatial=60, sigmaColor=0.4)\n",
    "                \n",
    "                else:\n",
    "                    title, fused = func(images)\n",
    "                results.append((title, fused))\n",
    "            except Exception as e:\n",
    "                print(f\"Error in {name}: {str(e)}\")\n",
    "                return\n",
    "        \n",
    "        # Display fused images\n",
    "        fig, axes = plt.subplots(1, len(results), figsize=(20, 5))\n",
    "        if len(results) == 1:\n",
    "            axes = [axes]\n",
    "            \n",
    "        for ax, (title, img) in zip(axes, results):\n",
    "            ax.imshow(img)\n",
    "            ax.set_title(title)\n",
    "            ax.axis('off')\n",
    "        plt.show()\n",
    "        \n",
    "        # Calculate metrics\n",
    "        num_images = len(results)\n",
    "        metric_table = []\n",
    "        similarity_matrix = np.zeros((num_images, num_images, 2))\n",
    "        \n",
    "        # Calculate individual metrics\n",
    "        individual_metrics = []\n",
    "        for title, img in results:\n",
    "            entropy = calculate_entropy(img)\n",
    "            sf = spatial_frequency(img)\n",
    "            individual_metrics.append((entropy, sf))\n",
    "        \n",
    "        # Calculate pairwise metrics\n",
    "        for i in range(num_images):\n",
    "            for j in range(i, num_images):\n",
    "                ssim_val, psnr_val = calculate_metrics(results[i][1], results[j][1])\n",
    "                similarity_matrix[i, j] = (ssim_val, psnr_val)\n",
    "                similarity_matrix[j, i] = (ssim_val, psnr_val)\n",
    "        \n",
    "        # Display metrics\n",
    "        df_individual = pd.DataFrame([(title, f\"{entropy:.4f}\", f\"{sf:.4f}\") \n",
    "                                    for (title, _), (entropy, sf) in zip(results, individual_metrics)],\n",
    "                                columns=['Method', 'Entropy', 'Spatial Frequency'])\n",
    "        \n",
    "        # Style individual metrics table\n",
    "        individual_styler = (df_individual.style\n",
    "                            .set_caption(\"Individual Image Metrics\")\n",
    "                            .set_properties(**{'text-align': 'left', \n",
    "                                            'font-size': '14px'})\n",
    "                            .hide(axis='index')\n",
    "                            .format(precision=4))\n",
    "        display(individual_styler)\n",
    "\n",
    "        # Create similarity matrices with NaN handling\n",
    "        methods = [title for title, _ in results]\n",
    "        \n",
    "        ssim_matrix = np.zeros((len(methods), len(methods)))\n",
    "        psnr_matrix = np.zeros((len(methods), len(methods)))\n",
    "        for i in range(len(methods)):\n",
    "            for j in range(len(methods)):\n",
    "                ssim_val, psnr_val = similarity_matrix[i, j]\n",
    "                ssim_matrix[i, j] = ssim_val\n",
    "                psnr_matrix[i, j] = psnr_val if not np.isinf(psnr_val) else np.nan\n",
    "\n",
    "        # Create formatted DataFrames\n",
    "        ssim_df = pd.DataFrame(ssim_matrix, index=methods, columns=methods)\n",
    "        psnr_df = pd.DataFrame(psnr_matrix, index=methods, columns=methods)\n",
    "\n",
    "        # Formatting functions with special handling\n",
    "        def format_ssim(val):\n",
    "            return f\"{val:.3f}\" if not np.isnan(val) else \"\"\n",
    "            \n",
    "        def format_psnr(val):\n",
    "            if np.isinf(val):\n",
    "                return \"âˆž\"\n",
    "            if np.isnan(val):\n",
    "                return \"N/A\"\n",
    "            return f\"{val:.2f}\"\n",
    "\n",
    "        # Create styled tables with titles\n",
    "        print(\"\\n\")\n",
    "        ssim_styler = (ssim_df.style\n",
    "                    .set_caption(\"Structural Similarity Index (SSIM)\")\n",
    "                    .format(format_ssim)\n",
    "                    .background_gradient(cmap='Blues', axis=None, \n",
    "                                        vmin=0, vmax=1)\n",
    "                    .set_properties(**{'font-size': '12px'}))\n",
    "\n",
    "        # Update the PSNR styler creation\n",
    "        finite_psnr = psnr_df.replace([np.inf, -np.inf], np.nan)\n",
    "        vmin = finite_psnr.min().min()\n",
    "        vmax = finite_psnr.max().max()\n",
    "\n",
    "        psnr_styler = (psnr_df.style\n",
    "                    .set_caption(\"Peak Signal-to-Noise Ratio (PSNR)\")\n",
    "                    .format(format_psnr)\n",
    "                    .background_gradient(cmap='Greens', axis=None,\n",
    "                                        vmin=vmin, vmax=vmax,\n",
    "                                        subset=pd.IndexSlice[:, :])\n",
    "                    .set_properties(**{'font-size': '12px'}))\n",
    "        \n",
    "        display(ssim_styler)\n",
    "        print(\"\\n\")\n",
    "        display(psnr_styler)\n",
    "\n",
    "compare_button.on_click(on_compare_button_clicked)\n",
    "\n",
    "# Display the widgets\n",
    "display(widgets.VBox([checkboxes_box, compare_button, output]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projectVenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
