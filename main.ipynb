{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imgTransformations\n",
    "import utils_jupyter\n",
    "import utils\n",
    "\n",
    "import os\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initilize path for images\n",
    "dirname = os.path.abspath('')\n",
    "folder = os.path.join(dirname, 'MEFDatabase/source image sequences/')\n",
    "images = [] \n",
    "\n",
    "# Pass the images list to the interactive selector\n",
    "utils_jupyter.interactive_image_selector(folder, images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definisci qua i metodi e inseriscili nel dizionario qua sotto, NON CAMBIARE I NOMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = {\n",
    "    'Average Fusion': imgTransformations.average_fusion,\n",
    "    'Mertens Fusion': imgTransformations.mertens_fusion,\n",
    "    'Laplacian Pyramid': imgTransformations.laplacian_pyramid_fusion,\n",
    "    'Exposure Fusion' : imgTransformations.exposure_fusion,\n",
    "    'Exposure Compensation': imgTransformations.exposure_compensation_fusion,\n",
    "    'Enhanced Exposure': imgTransformations.enhanced_exposure_fusion,\n",
    "    'Domain Transform': imgTransformations.domain_transform_fusion,\n",
    "    'Domain Transform - Homebrew': imgTransformations.domain_transform_fusion,\n",
    "    'Wavelet Fusion': imgTransformations.wavelet_fusion\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interactive MEF Method Explorer\n",
    "\n",
    "This widget showcases Multi-Exposure Fusion (MEF) techniques with real-time parameter tuning.\n",
    "Features tabbed interfaces for 8 fusion methods, including Laplacian Pyramid, Domain Transform, and Wavelet Fusion. Adjust sliders to optimize sigma/epsilon/levels and instantly visualize results with fused images and RGB histograms. Designed for rapid comparison of fusion outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils_jupyter.showcase_methods_tab(images, methods)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Domain Transform Filter  \n",
    "A edge-preserving smoothing technique that:  \n",
    "- Treats the image as a 3D surface (x,y,intensity)  \n",
    "- Performs anisotropic diffusion along intensity gradients  \n",
    "- Controlled by two parameters:  \n",
    "  - σₛ (spatial): Controls geometric smoothness (60px in this implementation)  \n",
    "  - σ꜀ (color): Preserves edges with similar intensity (0.4 = ±102/255 intensity tolerance)  \n",
    "\n",
    "### Weight Map Calculation for Exposure Fusion  \n",
    "`calculate_weight_maps(img)` computes pixel-wise fusion weights using three quality metrics:  \n",
    "\n",
    "1. **Contrast** (∇²): Calculated via Laplacian operator on grayscale intensity, highlighting edges and textures where \n",
    "```math \n",
    "L(x,y) = |∂²I/∂x² + ∂²I/∂y²|\n",
    "``` \n",
    "\n",
    "2. **Saturation**: Measured as standard deviation across RGB channels, favoring vibrant colors  \n",
    " ```math\n",
    " σ = √(Σ(Iᵢ - μ)²/3)\n",
    " ```\n",
    "\n",
    "3. **Well-exposedness**: Gaussian probability that penalizes over/under-exposed pixels (μ=0.5 represents ideal mid-tone exposure)  \n",
    "```math\n",
    " exp(-(I-0.5)²/(2×0.2²)\n",
    " ```\n",
    "\n",
    "The combined weight map is computed as:  \n",
    "```math\n",
    "W(x,y) = (L(x,y)+ε) × (σ(x,y)+ε) × (E(x,y)+ε)\n",
    "```\n",
    "where ε=1e⁻⁶ ensures numerical stability during normalization.  \n",
    "\n",
    "The function returns:  \n",
    "1. Raw weight map  \n",
    "2. Homebrew DT-filtered version (iterative bilateral filtering approximation)  \n",
    "3. OpenCV's optimized DT-filter result  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_weight_maps(img):\n",
    "    epsilon = 1e-6\n",
    "\n",
    "    guidance = img.astype(np.float32) / 255.0\n",
    "\n",
    "    gray = cv2.cvtColor((img * 255).astype(np.uint8), cv2.COLOR_RGB2GRAY)\n",
    "    contrast = np.abs(cv2.Laplacian(gray, cv2.CV_32F))\n",
    "\n",
    "    saturation = np.std(img, axis=2)\n",
    "\n",
    "    well_exposedness = np.exp(-0.5 * ((img - 0.5) / 0.2) ** 2)\n",
    "    well_exposedness = np.prod(well_exposedness, axis=2)\n",
    "\n",
    "    weight = (contrast + epsilon) * (saturation + epsilon) * (well_exposedness + epsilon)\n",
    "\n",
    "    # Apply Homebrew Domain Transform filter\n",
    "    smooth_weight_homebrew = imgTransformations.dt_filter_homebrew(guidance, weight, sigmaSpatial=60, sigmaColor=0.4, num_iterations=2)\n",
    "\n",
    "    # Apply OpenCV's dtFilter\n",
    "    smooth_weight_opencv = cv2.ximgproc.dtFilter(img, weight.astype(np.float32), sigmaSpatial=60, sigmaColor=0.4, mode=1)\n",
    "    \n",
    "    return weight, smooth_weight_homebrew, smooth_weight_opencv\n",
    "\n",
    "\n",
    "utils_jupyter.showcase_weight_maps_tab(images, calculate_weight_maps)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#comparison between homebrew and opencv dt filter\n",
    "title, fused = methods[\"Domain Transform\"](images, homebrew_dt=False)\n",
    "title_hb, fused_hb = methods[\"Domain Transform\"](images, homebrew_dt=True)\n",
    "\n",
    "plt.figure(figsize=(18, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(fused)\n",
    "plt.title(title)\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(fused_hb)\n",
    "plt.title(title_hb)\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Quality Analysis Functions\n",
    "\n",
    "### 1. Entropy Calculation\n",
    "\n",
    "Measures the **information content** in an image using Shannon entropy. For each RGB channel:\n",
    "\n",
    "1. **Histogram Creation**:  \n",
    "   Counts pixel intensity occurrences across 256 bins (0-255 range).\n",
    "\n",
    "2. **Probability Distribution**:  \n",
    "   Converts counts to probabilities:  \n",
    "   ```math\n",
    "   p(i) = \\frac{\\text{count}(i)}{\\text{total pixels}}\n",
    "   ```\n",
    "\n",
    "3. **Entropy Calculation**:  \n",
    "   Computes average surprise per pixel:  \n",
    "   ```math\n",
    "   H = -\\sum_{i=0}^{255} p(i) \\cdot \\log_2 p(i)\n",
    "   ```  \n",
    "   (Zero probabilities are excluded to avoid mathematical errors)\n",
    "\n",
    "The final result averages entropy values across all three color channels.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Spatial Frequency Calculation\n",
    "Quantifies **edge activity** through gradient analysis. For each RGB channel:\n",
    "\n",
    "1. **Horizontal Variation (RF)**:  \n",
    "   Measures row-wise differences:  \n",
    "   ```math\n",
    "   RF = \\sqrt{\\frac{1}{MN} \\sum_{x=1}^{M-1} \\sum_{y=0}^{N-1} [I(x,y) - I(x-1,y)]^2}\n",
    "   ```\n",
    "\n",
    "2. **Vertical Variation (CF)**:  \n",
    "   Measures column-wise differences:  \n",
    "   ```math\n",
    "   CF = \\sqrt{\\frac{1}{MN} \\sum_{x=0}^{M-1} \\sum_{y=1}^{N-1} [I(x,y) - I(x,y-1)]^2}\n",
    "   ```\n",
    "\n",
    "3. **Combined Metric**:  \n",
    "   Merges directions using vector magnitude:  \n",
    "   ```math\n",
    "   SF = \\sqrt{RF^2 + CF^2}\n",
    "   ```\n",
    "\n",
    "The final output averages spatial frequency across all channels.\n",
    "\n",
    "---\n",
    "\n",
    "### Key Characteristics Comparison\n",
    "\n",
    "| Aspect              | Entropy                          | Spatial Frequency               |\n",
    "|---------------------|----------------------------------|----------------------------------|\n",
    "| **What it measures** | Randomness in pixel values      | Intensity changes between pixels |\n",
    "| **High values mean** | Complex textures/variation      | Sharp edges/strong transitions   |\n",
    "| **Mathematical base**| Information theory              | Gradient energy analysis         |\n",
    "| **Typical range**   | 0-8 bits (8bpp images)          | 0-50 (image size dependent)      |\n",
    "| **Usage scenario**  | Assessing texture preservation  | Evaluating edge sharpness        |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_entropy(image):\n",
    "    \"\"\"Calculates entropy for an RGB image by averaging entropy across channels.\"\"\"\n",
    "    entropy_values = []\n",
    "    for channel in range(image.shape[-1]):  # Loop through R, G, B channels\n",
    "        hist, _ = np.histogram(image[:, :, channel].ravel(), bins=256, range=(0, 256))\n",
    "        hist = hist.astype(np.float32) / hist.sum()\n",
    "        hist = hist[hist > 0]  # Remove zero probabilities\n",
    "        entropy_values.append(-np.sum(hist * np.log2(hist)))\n",
    "    return np.mean(entropy_values)  # Average entropy across channels\n",
    "\n",
    "def spatial_frequency(image):\n",
    "    \"\"\"Calculates spatial frequency for an RGB image.\"\"\"\n",
    "    sf_values = []\n",
    "    for channel in range(image.shape[-1]):  # Compute SF for each color channel\n",
    "        rows, cols = image.shape[:2]\n",
    "        row_freq = np.sqrt(np.sum(np.diff(image[:, :, channel], axis=0) ** 2) / (rows * cols))\n",
    "        col_freq = np.sqrt(np.sum(np.diff(image[:, :, channel], axis=1) ** 2) / (rows * cols))\n",
    "        sf_values.append(np.sqrt(row_freq**2 + col_freq**2))\n",
    "    return np.mean(sf_values)  # Average SF across channels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding Similarity Metrics: SSIM and PSNR\n",
    "\n",
    "### Overview\n",
    "\n",
    "The function `calculate_metrics_comparison` compares two images using two popular similarity metrics:\n",
    "- **SSIM (Structural Similarity Index Measure)**\n",
    "- **PSNR (Peak Signal-to-Noise Ratio)**\n",
    "\n",
    "These metrics help quantify how similar two images are, which is particularly useful in image processing tasks such as image compression, restoration, and quality assessment.\n",
    "\n",
    "### 1. SSIM (Structural Similarity Index Measure)\n",
    "\n",
    "#### Mathematical Explanation\n",
    "SSIM measures the perceptual similarity between two images by comparing their luminance, contrast, and structural information. Although the complete formula is complex, a simplified version is:\n",
    "\n",
    "```math\n",
    "SSIM(x, y) = \\frac{(2 \\mu_x \\mu_y + C_1)(2 \\sigma_{xy} + C_2)}{(\\mu_x^2 + \\mu_y^2 + C_1)(\\sigma_x^2 + \\sigma_y^2 + C_2)}\n",
    "```\n",
    "\n",
    "where:\n",
    "- $\\mu_x $ and $ \\mu_y $ are the mean intensities of images `x` and `y`.\n",
    "- $ \\sigma_x^2 $ and $ \\sigma_y^2 $ are the variances of `x` and `y`.\n",
    "- $ \\sigma_{xy} $ is the covariance between `x` and `y`.\n",
    "- $ C_1 $ and $ C_2 $ are constants to stabilize the division when denominators are close to zero.\n",
    "\n",
    "### 2. PSNR (Peak Signal-to-Noise Ratio)\n",
    "\n",
    "#### Mathematical Explanation\n",
    "PSNR measures the quality of a reconstructed image compared to its original version. It is calculated using the Mean Squared Error (MSE) between the images. The formula for PSNR is:\n",
    "\n",
    "```math\n",
    "PSNR = 20 \\cdot \\log_{10}(MAX_I) - 10 \\cdot \\log_{10}(MSE)\n",
    "```\n",
    "\n",
    "where:\n",
    "- $ MAX_I $ is the maximum possible pixel value (255 for 8-bit images).\n",
    "- **MSE** is the Mean Squared Error between the two images, defined as:\n",
    "\n",
    "```math\n",
    "MSE = \\frac{1}{M \\times N} \\sum_{x,y} \\left[ I_1(x, y) - I_2(x, y) \\right]^2\n",
    "```\n",
    "\n",
    "If the MSE is zero (meaning the images are identical), PSNR is set to infinity.\n",
    "\n",
    "### Process of the Algorithm\n",
    "\n",
    "1. **Input Validation and Preprocessing:**\n",
    "   - **Dimension Check:** The function first verifies whether the two images have the same shape. If not, it resizes the second image to match the dimensions of the first.\n",
    "   - **Grayscale Conversion:** Both images are converted from RGB to grayscale, as SSIM and PSNR are typically calculated on single-channel images.\n",
    "\n",
    "2. **SSIM Calculation:**\n",
    "   - The SSIM metric is computed using the grayscale images to assess the structural similarity between them.\n",
    "\n",
    "3. **PSNR Calculation:**\n",
    "   - **MSE Calculation:** The Mean Squared Error between the two grayscale images is computed.\n",
    "   - **PSNR Formula:** If the MSE is zero, PSNR is set to infinity. Otherwise, PSNR is calculated using the logarithmic formula based on the MSE.\n",
    "\n",
    "4. **Output:**\n",
    "   - The function returns two values: the SSIM value (`ssim_value`) and the PSNR value (`psnr_value`).\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "- **SSIM** provides a measure of the perceptual similarity between images by taking into account luminance, contrast, and structural differences.\n",
    "- **PSNR** quantifies the error between images, with higher values indicating better image quality.\n",
    "- Together, these metrics are essential for comparing image quality and guiding improvements in image processing tasks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics_comparison(img1, img2):\n",
    "    \"\"\"Calculate similarity metrics between two images\"\"\"\n",
    "    if img1.shape != img2.shape:\n",
    "        img2 = cv2.resize(img2, (img1.shape[1], img1.shape[0]))\n",
    "    \n",
    "    # Convert to grayscale for SSIM/PSNR\n",
    "    gray1 = cv2.cvtColor(img1, cv2.COLOR_RGB2GRAY)\n",
    "    gray2 = cv2.cvtColor(img2, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    # Calculate SSIM\n",
    "    ssim_value = ssim(gray1, gray2, data_range=255)\n",
    "    \n",
    "    # Calculate PSNR with error handling\n",
    "    mse = np.mean((gray1 - gray2) ** 2)\n",
    "    if mse == 0:\n",
    "        psnr_value = np.inf\n",
    "    else:\n",
    "        with np.errstate(divide='ignore'):\n",
    "            psnr_value = 20 * np.log10(255) - 10 * np.log10(mse)\n",
    "    \n",
    "    return ssim_value, psnr_value\n",
    "\n",
    "utils_jupyter.compare_methods_and_metrics(spatial_frequency, calculate_entropy, calculate_metrics_comparison, images, methods)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing Images with Heatmaps and RGB Histograms\n",
    "\n",
    "This snippet performs the following tasks:\n",
    "\n",
    "- **Compute Difference:**  \n",
    "  Calculates the absolute per-pixel difference between two images to highlight changes.\n",
    "\n",
    "- **Generate Heatmap:**  \n",
    "  Converts the difference image to grayscale and displays it as a heatmap using a \"hot\" color map to visualize intensity differences.\n",
    "\n",
    "- **Display Comparisons:**  \n",
    "  Uses a utility function to compare multiple images by showing their difference heatmaps alongside their RGB histograms, providing insights into color distribution and changes.\n",
    "\n",
    "This approach is useful for tasks like image quality assessment and change detection.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_difference(image1, image2):\n",
    "    \"\"\"Compute absolute difference between two images.\"\"\"\n",
    "    return cv2.absdiff(image1, image2)\n",
    "\n",
    "def show_heatmap(diff_image):\n",
    "    \"\"\"Display a heatmap of the differences.\"\"\"\n",
    "    diff_gray = cv2.cvtColor(diff_image, cv2.COLOR_RGB2GRAY)\n",
    "    plt.imshow(diff_gray, cmap='hot', interpolation='nearest')\n",
    "    plt.colorbar()\n",
    "    plt.title(\"Difference Heatmap\")\n",
    "    plt.show()\n",
    "\n",
    "utils_jupyter.compare_methods_display(images, compute_difference, show_heatmap, methods)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
